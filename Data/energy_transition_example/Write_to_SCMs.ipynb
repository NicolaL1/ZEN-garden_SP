{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T09:23:40.317415Z",
     "start_time": "2025-04-27T09:23:39.873484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#create CSV output from ESM\n",
    "\n",
    "from zen_garden.postprocess.results import Results\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "#change according to your setup\n",
    "dataset_name = \"esm_pv_wind\"\n",
    "base_path = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data\\energy_transition_example\\outputs\")\n",
    "results_path = base_path / dataset_name\n",
    "output_dir = Path(\"./CSV_output\") / dataset_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- Load Results ----------------\n",
    "res_basic = Results(results_path)\n",
    "\n",
    "capacity = res_basic.get_full_ts(\"capacity\").reset_index()\n",
    "capacity_addition = res_basic.get_full_ts(\"capacity_addition\").reset_index()\n",
    "capacity_previous = res_basic.get_full_ts(\"capacity_previous\").reset_index()\n",
    "\n",
    "# ---------------- Filter Technologies ----------------\n",
    "selected_technologies = {\"heat_pump\", \"photovoltaics\", \"wind_offshore\", \"wind_onshore\"}\n",
    "\n",
    "capacity = capacity[capacity[\"technology\"].isin(selected_technologies)]\n",
    "capacity_addition = capacity_addition[capacity_addition[\"technology\"].isin(selected_technologies)]\n",
    "capacity_previous = capacity_previous[capacity_previous[\"technology\"].isin(selected_technologies)]\n",
    "\n",
    "# ---------------- Adjust capacity_addition[\"0\"] by subtracting capacity_previous[\"0\"] ----------------\n",
    "# Ensure all year columns are strings\n",
    "capacity_addition.columns = capacity_addition.columns.map(str)\n",
    "capacity_previous.columns = capacity_previous.columns.map(str)\n",
    "\n",
    "# Identify the first year column (usually '0')\n",
    "year_cols = [col for col in capacity_addition.columns if col.isdigit()]\n",
    "first_year_col = min(year_cols, key=int)\n",
    "\n",
    "# Prepare capacity_previous for merging\n",
    "cap_prev_trimmed = capacity_previous[[\"technology\", \"capacity_type\", \"location\", first_year_col]].copy()\n",
    "cap_prev_trimmed = cap_prev_trimmed.rename(columns={first_year_col: \"previous_capacity\"})\n",
    "\n",
    "# Merge and subtract\n",
    "capacity_addition = pd.merge(\n",
    "    capacity_addition,\n",
    "    cap_prev_trimmed,\n",
    "    on=[\"technology\", \"capacity_type\", \"location\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "capacity_addition[first_year_col] = capacity_addition[first_year_col] - capacity_addition[\"previous_capacity\"].fillna(0)\n",
    "capacity_addition[first_year_col] = capacity_addition[first_year_col].clip(lower=0)\n",
    "capacity_addition = capacity_addition.drop(columns=[\"previous_capacity\"])\n",
    "\n",
    "# ---------------- Save Filtered CSVs ----------------\n",
    "# and round to 4 decimal digits\n",
    "capacity.round(4).to_csv(output_dir / \"capacity.csv\", index=False)\n",
    "capacity_addition.round(4).to_csv(output_dir / \"capacity_addition.csv\", index=False)\n",
    "capacity_previous.round(4).to_csv(output_dir / \"capacity_previous.csv\", index=False)\n",
    "\n",
    "# ---------------- Aggregation Setup ----------------\n",
    "specific_locations = {\"DE\", \"CH\"}\n",
    "all_locations = set(capacity[\"location\"].unique())\n",
    "roe_locations = all_locations - specific_locations\n",
    "\n",
    "\n",
    "def aggregate_by_location(df, location_set, location_name):\n",
    "    return (\n",
    "        df[df[\"location\"].isin(location_set)]\n",
    "        .groupby([\"technology\", \"capacity_type\"])\n",
    "        .sum(numeric_only=True)\n",
    "        .assign(location=location_name)\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- Aggregate Data ----------------\n",
    "capacity_aggregated = pd.concat([\n",
    "    aggregate_by_location(capacity, {\"DE\"}, \"DE\"),\n",
    "    aggregate_by_location(capacity, {\"CH\"}, \"CH\"),\n",
    "    aggregate_by_location(capacity, roe_locations, \"ROE\")\n",
    "]).reset_index()\n",
    "\n",
    "capacity_addition_aggregated = pd.concat([\n",
    "    aggregate_by_location(capacity_addition, {\"DE\"}, \"DE\"),\n",
    "    aggregate_by_location(capacity_addition, {\"CH\"}, \"CH\"),\n",
    "    aggregate_by_location(capacity_addition, roe_locations, \"ROE\")\n",
    "]).reset_index()\n",
    "\n",
    "# ---------------- Save Aggregated CSVs ----------------\n",
    "capacity_aggregated.round(4).to_csv(output_dir / \"capacity_aggregated_by_location.csv\", index=False)\n",
    "capacity_addition_aggregated.round(4).to_csv(output_dir / \"capacity_addition_aggregated_by_location.csv\", index=False)\n",
    "\n",
    "print(f\"✅ All CSV files for dataset '{dataset_name}' saved successfully in: {output_dir}\")"
   ],
   "id": "dad95eb0ccac631f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All CSV files for dataset 'energy_transition_ref_2021' saved successfully in: CSV_output\\energy_transition_ref_2021\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T09:23:40.430530Z",
     "start_time": "2025-04-27T09:23:40.368033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Update aggregated CSV column headers with actual years from system.json ---\n",
    "import json\n",
    "# Load system.json\n",
    "system_path = base_path.parent / dataset_name / \"system.json\"\n",
    "with open(system_path, \"r\") as f:\n",
    "    system_config = json.load(f)\n",
    "\n",
    "reference_year = system_config[\"reference_year\"]\n",
    "interval = system_config[\"interval_between_years\"]\n",
    "optimized_years = system_config[\"optimized_years\"]\n",
    "year_labels = [str(reference_year + i * interval) for i in range(optimized_years)]\n",
    "\n",
    "# Create rename mapping from '0', '1', ... to actual year labels\n",
    "rename_columns = {str(i): year_labels[i] for i in range(len(year_labels))}\n",
    "\n",
    "# Function to rename year columns in a CSV\n",
    "def rename_year_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.rename(columns=rename_columns)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Renamed year columns in: {csv_path}\")\n",
    "\n",
    "# Apply to both aggregated files\n",
    "rename_year_columns(output_dir / \"capacity_aggregated_by_location.csv\")\n",
    "rename_year_columns(output_dir / \"capacity_addition_aggregated_by_location.csv\")\n"
   ],
   "id": "6252e0fc961c0ce1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed year columns in: CSV_output\\energy_transition_ref_2021\\capacity_aggregated_by_location.csv\n",
      "Renamed year columns in: CSV_output\\energy_transition_ref_2021\\capacity_addition_aggregated_by_location.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T09:23:40.483724Z",
     "start_time": "2025-04-27T09:23:40.440536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#specific for PV (write values to demand_yearly_variation.csv)\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "dataset_name = \"energy_transition_ref_2021\"\n",
    "\n",
    "# Base paths\n",
    "base_path = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data\\energy_transition_example\\outputs\")\n",
    "output_dir = Path(\"./CSV_output\") / dataset_name\n",
    "esm_capacity_path = output_dir / \"capacity_addition_aggregated_by_location.csv\"\n",
    "\n",
    "original_dir = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_PV\\01_SP_MV_PV\")\n",
    "new_dir = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_PV\\01_SP_MV_PV_new\")\n",
    "original_dyv_path = original_dir / \"set_carriers\" / \"pv_module\" / \"demand_yearly_variation.csv\"\n",
    "target_dyv_path = new_dir / \"set_carriers\" / \"pv_module\" / \"demand_yearly_variation.csv\"\n",
    "\n",
    "# --- Step 1: Clone the original directory ---\n",
    "if new_dir.exists():\n",
    "    print(f\"Directory already exists: {new_dir}\")\n",
    "else:\n",
    "    shutil.copytree(original_dir, new_dir)\n",
    "    print(f\"Created clone of wind model input: {new_dir}\")\n",
    "\n",
    "# --- Step 2: Load year labels from system.json ---\n",
    "system_path = base_path.parent / dataset_name / \"system.json\"\n",
    "with open(system_path, \"r\") as f:\n",
    "    system_config = json.load(f)\n",
    "\n",
    "reference_year = system_config[\"reference_year\"]\n",
    "interval = system_config[\"interval_between_years\"]\n",
    "optimized_years = system_config[\"optimized_years\"]\n",
    "year_labels = [str(reference_year + i * interval) for i in range(optimized_years)]\n",
    "\n",
    "# --- Step 3: Load original demand_yearly_variation to preserve all nodes ---\n",
    "df_existing = pd.read_csv(original_dyv_path)\n",
    "\n",
    "# --- Step 4: Prepare updated PV data from ESM ---\n",
    "country_map = {\n",
    "    \"DE\": \"DEU\",\n",
    "    \"CH\": \"CHE\",\n",
    "    \"AT\": \"AUT\",\n",
    "    \"NL\": \"NLD\",\n",
    "    \"ROE\": \"ROE\",\n",
    "    \"ROW\": \"ROW\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(esm_capacity_path)\n",
    "df_photovoltaics = df[df[\"technology\"] == \"photovoltaics\"]\n",
    "df_grouped = df_photovoltaics.groupby([\"location\"]).sum(numeric_only=True).reset_index()\n",
    "df_grouped[\"node\"] = df_grouped[\"location\"].map(country_map)\n",
    "df_grouped = df_grouped[df_grouped[\"node\"].notna()].drop(columns=[\"location\"])\n",
    "\n",
    "# Transpose to match demand_yearly_variation structure\n",
    "df_new = df_grouped.set_index(\"node\").T\n",
    "df_new.index.name = \"year\"\n",
    "df_new = df_new.reset_index()\n",
    "\n",
    "# Fix year column using actual labels from system.json\n",
    "df_new[\"year\"] = year_labels[:len(df_new)]\n",
    "df_new[\"year\"] = df_new[\"year\"].astype(str)\n",
    "df_existing[\"year\"] = df_existing[\"year\"].astype(str)\n",
    "\n",
    "# Set year as index for merging\n",
    "df_new = df_new.set_index(\"year\")\n",
    "df_existing = df_existing.set_index(\"year\")\n",
    "\n",
    "# --- DEBUG: Check alignment before merge ---\n",
    "print(\"✅ Columns available in new data:\", df_new.columns.tolist())\n",
    "print(\"✅ Columns in existing file:\", df_existing.columns.tolist())\n",
    "print(\"✅ Years in new data:\", df_new.index.tolist())\n",
    "print(\"✅ Years in existing file:\", df_existing.index.tolist())\n",
    "\n",
    "# --- Step 5: Merge values only for matching columns ---\n",
    "updated_cols = [col for col in df_new.columns if col in df_existing.columns]\n",
    "print(\"🔄 Columns being updated:\", updated_cols)\n",
    "\n",
    "for col in updated_cols:\n",
    "    df_existing[col] = df_new[col].combine_first(df_existing[col])\n",
    "\n",
    "# --- Step 6: Save final file ---\n",
    "df_result = df_existing.reset_index()\n",
    "df_result.to_csv(target_dyv_path, index=False)\n",
    "print(f\"✅ Final demand_yearly_variation.csv written to:\\n{target_dyv_path}\")"
   ],
   "id": "5b33d03d2e2ba791",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_PV\\01_SP_MV_PV_new\n",
      "✅ Columns available in new data: ['CHE', 'DEU', 'ROE']\n",
      "✅ Columns in existing file: ['CHE', 'CHN', 'DEU', 'IND', 'KOR', 'MYS', 'ROA', 'ROE', 'ROW', 'THA', 'USA', 'VNM']\n",
      "✅ Years in new data: ['2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030']\n",
      "✅ Years in existing file: ['2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030']\n",
      "🔄 Columns being updated: ['CHE', 'DEU', 'ROE']\n",
      "✅ Final demand_yearly_variation.csv written to:\n",
      "C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_PV\\01_SP_MV_PV_new\\set_carriers\\pv_module\\demand_yearly_variation.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T09:23:40.627948Z",
     "start_time": "2025-04-27T09:23:40.583150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#specific for wind (write values to demand_yearly_variation.csv)\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "dataset_name = \"energy_transition_ref_2021\"\n",
    "\n",
    "# Base paths\n",
    "base_path = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data\\energy_transition_example\\outputs\")\n",
    "output_dir = Path(\"./CSV_output\") / dataset_name\n",
    "esm_capacity_path = output_dir / \"capacity_addition_aggregated_by_location.csv\"\n",
    "\n",
    "original_dir = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_Wind\\Data_WT\")\n",
    "new_dir = Path(r\"C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_Wind\\Data_WT_new\")\n",
    "original_dyv_path = original_dir / \"set_carriers\" / \"Turbine\" / \"demand_yearly_variation.csv\"\n",
    "target_dyv_path = new_dir / \"set_carriers\" / \"Turbine\" / \"demand_yearly_variation.csv\"\n",
    "\n",
    "# --- Step 1: Clone the original directory ---\n",
    "if new_dir.exists():\n",
    "    print(f\"Directory already exists: {new_dir}\")\n",
    "else:\n",
    "    shutil.copytree(original_dir, new_dir)\n",
    "    print(f\"Created clone of wind model input: {new_dir}\")\n",
    "\n",
    "# --- Step 2: Load year labels from system.json ---\n",
    "system_path = base_path.parent / dataset_name / \"system.json\"\n",
    "with open(system_path, \"r\") as f:\n",
    "    system_config = json.load(f)\n",
    "\n",
    "reference_year = system_config[\"reference_year\"]\n",
    "interval = system_config[\"interval_between_years\"]\n",
    "optimized_years = system_config[\"optimized_years\"]\n",
    "year_labels = [str(reference_year + i * interval) for i in range(optimized_years)]\n",
    "\n",
    "# --- Step 3: Load original demand_yearly_variation to preserve all nodes ---\n",
    "df_existing = pd.read_csv(original_dyv_path)\n",
    "\n",
    "# --- Step 4: Prepare updated wind data from ESM ---\n",
    "country_map = {\n",
    "    \"DE\": \"DEU\",\n",
    "    \"CH\": \"CHE\",\n",
    "    \"AT\": \"AUT\",\n",
    "    \"NL\": \"NLD\",\n",
    "    \"ROE\": \"ROE\",\n",
    "    \"ROW\": \"ROW\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(esm_capacity_path)\n",
    "df_wind = df[df[\"technology\"].isin([\"wind_onshore\", \"wind_offshore\"])]\n",
    "df_grouped = df_wind.groupby([\"location\"]).sum(numeric_only=True).reset_index()\n",
    "df_grouped[\"node\"] = df_grouped[\"location\"].map(country_map)\n",
    "df_grouped = df_grouped[df_grouped[\"node\"].notna()].drop(columns=[\"location\"])\n",
    "\n",
    "# Transpose to match demand_yearly_variation structure\n",
    "df_new = df_grouped.set_index(\"node\").T\n",
    "df_new.index.name = \"year\"\n",
    "df_new = df_new.reset_index()\n",
    "\n",
    "# Fix year column using actual labels from system.json\n",
    "df_new[\"year\"] = year_labels[:len(df_new)]\n",
    "df_new[\"year\"] = df_new[\"year\"].astype(str)\n",
    "df_existing[\"year\"] = df_existing[\"year\"].astype(str)\n",
    "\n",
    "# Set year as index for merging\n",
    "df_new = df_new.set_index(\"year\")\n",
    "df_existing = df_existing.set_index(\"year\")\n",
    "\n",
    "# --- DEBUG: Check alignment before merge ---\n",
    "print(\"✅ Columns available in new data:\", df_new.columns.tolist())\n",
    "print(\"✅ Columns in existing file:\", df_existing.columns.tolist())\n",
    "print(\"✅ Years in new data:\", df_new.index.tolist())\n",
    "print(\"✅ Years in existing file:\", df_existing.index.tolist())\n",
    "\n",
    "# --- Step 5: Merge values only for matching columns ---\n",
    "updated_cols = [col for col in df_new.columns if col in df_existing.columns]\n",
    "print(\"🔄 Columns being updated:\", updated_cols)\n",
    "\n",
    "for col in updated_cols:\n",
    "    df_existing[col] = df_new[col].combine_first(df_existing[col])\n",
    "\n",
    "# --- Step 6: Save final file ---\n",
    "df_result = df_existing.reset_index()\n",
    "df_result.to_csv(target_dyv_path, index=False)\n",
    "print(f\"✅ Final demand_yearly_variation.csv written to:\\n{target_dyv_path}\")\n"
   ],
   "id": "90ce45a34b681315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_Wind\\Data_WT_new\n",
      "✅ Columns available in new data: ['CHE', 'DEU', 'ROE']\n",
      "✅ Columns in existing file: ['AUS', 'BRA', 'CHE', 'CHN', 'DEU', 'DNK', 'GBR', 'IND', 'JPN', 'NLD', 'ROE', 'ROW', 'SWE', 'USA']\n",
      "✅ Years in new data: ['2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030']\n",
      "✅ Years in existing file: ['2021', '2022', '2023', '2024', '2025', '2026', '2027', '2028', '2029', '2030']\n",
      "🔄 Columns being updated: ['CHE', 'DEU', 'ROE']\n",
      "✅ Final demand_yearly_variation.csv written to:\n",
      "C:\\Users\\nicol\\GitHub\\ZEN-garden\\Data_Wind\\Data_WT_new\\set_carriers\\Turbine\\demand_yearly_variation.csv\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
